{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>By <font color=\"green\">Leigh Lin</font></h3>\n",
    "<br/>\n",
    "<font color=\"navy\">I have created this notebook to \n",
    "</font> \n",
    "<br>\n",
    "<font color=\"navy\">\n",
    "<ul>\n",
    "<li>demonstrate how various techniques can improve the score of CNN.(score  0.99657)</li>\n",
    "<li>show how Tensorboard can be used to visualize the data.</li>\n",
    "<li>show how to enable GPU at a Window laptop.</li>\n",
    "</ul>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.4'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras import layers\n",
    "from keras import models\n",
    "\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "from os import makedirs\n",
    "from os.path import exists, join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"navy\">Loading up data</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('C://projects//python//kaggle//digits-recognizer//data//digit-recognizer//train.csv')\n",
    "train.head()\n",
    "test = pd.read_csv('C://projects//python//kaggle//digits-recognizer//data//digit-recognizer//test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"navy\">Setting up train/test data</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = train.loc[:]['label']\n",
    "Y_train = Y_train.values\n",
    "X_train = train.iloc[:,1:]\n",
    "del train \n",
    "# Normalize the data\n",
    "X_train = X_train / 255.0\n",
    "test = test / 255.0\n",
    "# Reshape image in 3 dimensions (height = 28px, width = 28px , canal = 1)\n",
    "X_train = X_train.values.reshape(-1,28,28,1)\n",
    "test = test.values.reshape(-1,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed\n",
    "random_seed = 3\n",
    "batch_size=86  \n",
    "\n",
    "# Split the train and the validation set for the fitting\n",
    "X_train, X_val, Y_train, Y_val_original = train_test_split(X_train, Y_train, test_size = 0.1, random_state=random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"navy\">One hot encoding of labels</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels to one hot vectors (ex : 1 -> [0,1,0,0,0,0,0,0,0,0])\n",
    "Y_train = to_categorical(Y_train, num_classes = 10)\n",
    "Y_val = to_categorical(Y_val_original, num_classes = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"navy\">Create a simple CNN model.</font>\n",
    "<br/>\n",
    "<font color=\"navy\">Notice that we have not used dropout or batch-normalization.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                36928     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 93,322\n",
      "Trainable params: 93,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(filters = 32, kernel_size = (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(filters = 64, kernel_size = (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(filters = 64, kernel_size = (3, 3), activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\developer\\Anaconda3\\envs\\python36gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/30\n",
      "37800/37800 [==============================] - 38s 997us/step - loss: 0.2510 - acc: 0.9208 - val_loss: 0.0837 - val_acc: 0.9750\n",
      "Epoch 2/30\n",
      "37800/37800 [==============================] - 35s 938us/step - loss: 0.0590 - acc: 0.9808 - val_loss: 0.2018 - val_acc: 0.9360\n",
      "Epoch 3/30\n",
      "37800/37800 [==============================] - 35s 937us/step - loss: 0.0394 - acc: 0.9876 - val_loss: 0.0527 - val_acc: 0.9848\n",
      "Epoch 4/30\n",
      "37800/37800 [==============================] - 35s 935us/step - loss: 0.0303 - acc: 0.9904 - val_loss: 0.0436 - val_acc: 0.9879\n",
      "Epoch 5/30\n",
      "37800/37800 [==============================] - 37s 981us/step - loss: 0.0223 - acc: 0.9928 - val_loss: 0.0413 - val_acc: 0.9898\n",
      "Epoch 6/30\n",
      "37800/37800 [==============================] - 39s 1ms/step - loss: 0.0189 - acc: 0.9940 - val_loss: 0.0617 - val_acc: 0.9845\n",
      "Epoch 7/30\n",
      "37800/37800 [==============================] - 38s 1ms/step - loss: 0.0143 - acc: 0.9952 - val_loss: 0.0586 - val_acc: 0.9852\n",
      "Epoch 8/30\n",
      "37800/37800 [==============================] - 39s 1ms/step - loss: 0.0111 - acc: 0.9967 - val_loss: 0.0803 - val_acc: 0.9821\n",
      "Epoch 9/30\n",
      "37800/37800 [==============================] - 38s 1ms/step - loss: 0.0100 - acc: 0.9967 - val_loss: 0.0599 - val_acc: 0.9879\n",
      "Epoch 10/30\n",
      "37800/37800 [==============================] - 38s 1ms/step - loss: 0.0094 - acc: 0.9970 - val_loss: 0.0639 - val_acc: 0.9874\n",
      "Epoch 11/30\n",
      "37800/37800 [==============================] - 39s 1ms/step - loss: 0.0065 - acc: 0.9979 - val_loss: 0.0696 - val_acc: 0.9869\n",
      "Epoch 12/30\n",
      "37800/37800 [==============================] - 38s 996us/step - loss: 0.0060 - acc: 0.9982 - val_loss: 0.0737 - val_acc: 0.9883\n",
      "Epoch 13/30\n",
      "37800/37800 [==============================] - 36s 957us/step - loss: 0.0050 - acc: 0.9984 - val_loss: 0.0961 - val_acc: 0.9848\n",
      "Epoch 14/30\n",
      "37800/37800 [==============================] - 36s 950us/step - loss: 0.0040 - acc: 0.9989 - val_loss: 0.0830 - val_acc: 0.9881\n",
      "Epoch 15/30\n",
      "37800/37800 [==============================] - 33s 872us/step - loss: 0.0050 - acc: 0.9986 - val_loss: 0.0910 - val_acc: 0.9860\n",
      "Epoch 16/30\n",
      "37800/37800 [==============================] - 32s 859us/step - loss: 0.0040 - acc: 0.9989 - val_loss: 0.0832 - val_acc: 0.9874\n",
      "Epoch 17/30\n",
      "37800/37800 [==============================] - 34s 887us/step - loss: 0.0040 - acc: 0.9989 - val_loss: 0.1055 - val_acc: 0.9843\n",
      "Epoch 18/30\n",
      "37800/37800 [==============================] - 33s 882us/step - loss: 0.0033 - acc: 0.9990 - val_loss: 0.0826 - val_acc: 0.9871\n",
      "Epoch 19/30\n",
      "37800/37800 [==============================] - 41s 1ms/step - loss: 0.0036 - acc: 0.9989 - val_loss: 0.0829 - val_acc: 0.9874\n",
      "Epoch 20/30\n",
      "37800/37800 [==============================] - 36s 949us/step - loss: 0.0030 - acc: 0.9990 - val_loss: 0.0749 - val_acc: 0.9895\n",
      "Epoch 21/30\n",
      "37800/37800 [==============================] - 42s 1ms/step - loss: 0.0031 - acc: 0.9992 - val_loss: 0.0868 - val_acc: 0.9886\n",
      "Epoch 22/30\n",
      "37800/37800 [==============================] - 39s 1ms/step - loss: 0.0034 - acc: 0.9992 - val_loss: 0.0904 - val_acc: 0.9886\n",
      "Epoch 23/30\n",
      "37800/37800 [==============================] - 39s 1ms/step - loss: 0.0025 - acc: 0.9993 - val_loss: 0.1132 - val_acc: 0.9862\n",
      "Epoch 24/30\n",
      "37800/37800 [==============================] - 39s 1ms/step - loss: 0.0034 - acc: 0.9993 - val_loss: 0.0974 - val_acc: 0.9879\n",
      "Epoch 25/30\n",
      "37800/37800 [==============================] - 39s 1ms/step - loss: 0.0024 - acc: 0.9993 - val_loss: 0.0891 - val_acc: 0.9881\n",
      "Epoch 26/30\n",
      "37800/37800 [==============================] - 42s 1ms/step - loss: 0.0025 - acc: 0.9995 - val_loss: 0.1250 - val_acc: 0.9850\n",
      "Epoch 27/30\n",
      "37800/37800 [==============================] - 43s 1ms/step - loss: 0.0027 - acc: 0.9992 - val_loss: 0.0972 - val_acc: 0.9883\n",
      "Epoch 28/30\n",
      "37800/37800 [==============================] - 42s 1ms/step - loss: 0.0018 - acc: 0.9996 - val_loss: 0.1100 - val_acc: 0.9874\n",
      "Epoch 29/30\n",
      "37800/37800 [==============================] - 42s 1ms/step - loss: 0.0021 - acc: 0.9997 - val_loss: 0.1031 - val_acc: 0.9883\n",
      "Epoch 30/30\n",
      "37800/37800 [==============================] - 39s 1ms/step - loss: 0.0024 - acc: 0.9993 - val_loss: 0.1096 - val_acc: 0.9876\n",
      "Test loss: 0.10964801989353581\n",
      "Test accuracy: 0.9876190476190476\n"
     ]
    }
   ],
   "source": [
    "epochs=30 \n",
    "model.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_val, Y_val))\n",
    "score = model.evaluate(X_val, Y_val, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"navy\">The Test accuracy: </font><font color=\"green\">0.9876190476190476</font>    \n",
    "<font color=\"navy\">It is such a simple model. Obviously we can make some improments.\n",
    "<br/>The improvements we make are \n",
    "<ul/><li>Use data augmentation.</li>\n",
    "<li>Reduce learning rate when a metric has stopped improving.</li>\n",
    "<li>Use BatchNormalization.</li></ul>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.1, # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1)\n",
    "\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = 'C://projects//python//kaggle//digits-recognizer//logs'\n",
    "if not exists(log_dir):\n",
    "    makedirs(log_dir)\n",
    "    \n",
    "# save class labels to disk to color data points in TensorBoard accordingly\n",
    "with open(join(log_dir, 'metadata.tsv'), 'w') as f:\n",
    "    np.savetxt(f, Y_val_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard = TensorBoard(batch_size=batch_size,\n",
    "                          log_dir = log_dir,\n",
    "                          embeddings_freq=1,\n",
    "                          embeddings_layer_names=['features'],\n",
    "                          embeddings_metadata='metadata.tsv',\n",
    "                          embeddings_data=X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce learning rate when a metric has stopped improving\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                            patience=3, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.3, \n",
    "                                            min_lr=0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(filters = 32, kernel_size = (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "#model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.BatchNormalization()) \n",
    "model.add(layers.Conv2D(filters = 64, kernel_size = (3, 3), activation='relu'))\n",
    "#model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.BatchNormalization()) \n",
    "model.add(layers.Conv2D(filters = 64, kernel_size = (3, 3), activation='relu'))\n",
    "model.add(layers.BatchNormalization()) \n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu', name='features'))\n",
    "model.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"navy\">I have enabled GPU on my laptop. So the average time for one epoch is </font><font color=\"green\">21</font><font color=\"navy\"> seconds.</font>\n",
    "<br/>\n",
    "<font color=\"navy\">My laptop has a GeForce GTX 860M GPU. Window version is Window 8.1. It has an Intel i7 2.5GHz CPU.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"navy\">Test if the computer is using </font><font color=\"red\">GPU</font><font color=\"navy\"> version</font>\n",
    "<font color=\"navy\">If the result is </font><font color=\"green\">True</font><font color=\"navy\">, then you are using GPU.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "tf.test.is_built_with_cuda()\n",
    "tf.test.is_gpu_available(cuda_only=False, min_cuda_compute_capability=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"navy\">\n",
    "I have enabled GPU following the steps below.\n",
    "<ol>\n",
    "<li>Remove all NVIDIA Corporation software from your computer.</li>\n",
    "<li>Download and re-install NVIDIA driver</li>\n",
    "<li>Download and install Visual Studio 2019</li>\n",
    "<li>Download and install CUDA Toolkit for Windows 8.1</li>\n",
    "<li>Download and unzip cuDNN</li>\n",
    "<li>Install Tensorflow-gpu (using Anaconda)</li>\n",
    "</ol>\n",
    "Of course it is a simplifised version, maybe too simplifised. It is another blog to get all the details out.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "439/439 [==============================] - 22s 49ms/step - loss: 0.6311 - acc: 0.8688 - val_loss: 0.1649 - val_acc: 0.9690\n",
      "Epoch 2/40\n",
      "439/439 [==============================] - 21s 47ms/step - loss: 0.2249 - acc: 0.9504 - val_loss: 0.3352 - val_acc: 0.9512\n",
      "Epoch 3/40\n",
      "439/439 [==============================] - 21s 47ms/step - loss: 0.1643 - acc: 0.9644 - val_loss: 0.1388 - val_acc: 0.9724\n",
      "Epoch 4/40\n",
      "439/439 [==============================] - 21s 47ms/step - loss: 0.1155 - acc: 0.9722 - val_loss: 0.1089 - val_acc: 0.9786\n",
      "Epoch 5/40\n",
      "439/439 [==============================] - 21s 47ms/step - loss: 0.1002 - acc: 0.9764 - val_loss: 0.0897 - val_acc: 0.9831\n",
      "Epoch 6/40\n",
      "439/439 [==============================] - 21s 47ms/step - loss: 0.0957 - acc: 0.9779 - val_loss: 0.1381 - val_acc: 0.9771\n",
      "Epoch 7/40\n",
      "439/439 [==============================] - 21s 47ms/step - loss: 0.0893 - acc: 0.9792 - val_loss: 0.1007 - val_acc: 0.9824\n",
      "Epoch 8/40\n",
      "439/439 [==============================] - 21s 47ms/step - loss: 0.0830 - acc: 0.9810 - val_loss: 0.0992 - val_acc: 0.9831\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
      "Epoch 9/40\n",
      "439/439 [==============================] - 21s 47ms/step - loss: 0.0510 - acc: 0.9881 - val_loss: 0.0495 - val_acc: 0.9910\n",
      "Epoch 10/40\n",
      "439/439 [==============================] - 21s 47ms/step - loss: 0.0459 - acc: 0.9887 - val_loss: 0.0493 - val_acc: 0.9898\n",
      "Epoch 11/40\n",
      "439/439 [==============================] - 21s 47ms/step - loss: 0.0403 - acc: 0.9902 - val_loss: 0.0506 - val_acc: 0.9895\n",
      "Epoch 12/40\n",
      "439/439 [==============================] - 21s 48ms/step - loss: 0.0400 - acc: 0.9897 - val_loss: 0.0474 - val_acc: 0.9907\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
      "Epoch 13/40\n",
      "439/439 [==============================] - 21s 49ms/step - loss: 0.0339 - acc: 0.9919 - val_loss: 0.0491 - val_acc: 0.9910\n",
      "Epoch 14/40\n",
      "439/439 [==============================] - 21s 48ms/step - loss: 0.0296 - acc: 0.9923 - val_loss: 0.0476 - val_acc: 0.9910\n",
      "Epoch 15/40\n",
      "439/439 [==============================] - 21s 48ms/step - loss: 0.0323 - acc: 0.9920 - val_loss: 0.0425 - val_acc: 0.9905\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
      "Epoch 16/40\n",
      "439/439 [==============================] - 20s 46ms/step - loss: 0.0286 - acc: 0.9927 - val_loss: 0.0425 - val_acc: 0.9910\n",
      "Epoch 17/40\n",
      "439/439 [==============================] - 21s 47ms/step - loss: 0.0294 - acc: 0.9927 - val_loss: 0.0437 - val_acc: 0.9902\n",
      "Epoch 18/40\n",
      "439/439 [==============================] - 20s 46ms/step - loss: 0.0292 - acc: 0.9928 - val_loss: 0.0438 - val_acc: 0.9910\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 8.100000013655517e-06.\n",
      "Epoch 19/40\n",
      "439/439 [==============================] - 21s 48ms/step - loss: 0.0273 - acc: 0.9933 - val_loss: 0.0439 - val_acc: 0.9912\n",
      "Epoch 20/40\n",
      "439/439 [==============================] - 21s 48ms/step - loss: 0.0257 - acc: 0.9934 - val_loss: 0.0428 - val_acc: 0.9914\n",
      "Epoch 21/40\n",
      "439/439 [==============================] - 21s 48ms/step - loss: 0.0242 - acc: 0.9938 - val_loss: 0.0432 - val_acc: 0.9912\n",
      "Epoch 22/40\n",
      "439/439 [==============================] - 21s 48ms/step - loss: 0.0275 - acc: 0.9934 - val_loss: 0.0421 - val_acc: 0.9910\n",
      "Epoch 23/40\n",
      "439/439 [==============================] - 21s 48ms/step - loss: 0.0266 - acc: 0.9929 - val_loss: 0.0425 - val_acc: 0.9905\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 2.429999949526973e-06.\n",
      "Epoch 24/40\n",
      "439/439 [==============================] - 21s 48ms/step - loss: 0.0251 - acc: 0.9940 - val_loss: 0.0424 - val_acc: 0.9910\n",
      "Epoch 25/40\n",
      "439/439 [==============================] - 21s 48ms/step - loss: 0.0272 - acc: 0.9933 - val_loss: 0.0424 - val_acc: 0.9905\n",
      "Epoch 26/40\n",
      "439/439 [==============================] - 21s 48ms/step - loss: 0.0304 - acc: 0.9929 - val_loss: 0.0423 - val_acc: 0.9905\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "Epoch 27/40\n",
      "439/439 [==============================] - 21s 47ms/step - loss: 0.0237 - acc: 0.9934 - val_loss: 0.0421 - val_acc: 0.9910\n",
      "Epoch 28/40\n",
      "439/439 [==============================] - 21s 47ms/step - loss: 0.0247 - acc: 0.9933 - val_loss: 0.0421 - val_acc: 0.9910\n",
      "Epoch 29/40\n",
      "439/439 [==============================] - 21s 47ms/step - loss: 0.0301 - acc: 0.9925 - val_loss: 0.0422 - val_acc: 0.9910\n",
      "Epoch 30/40\n",
      "439/439 [==============================] - 21s 47ms/step - loss: 0.0240 - acc: 0.9936 - val_loss: 0.0423 - val_acc: 0.9910\n",
      "Epoch 31/40\n",
      "439/439 [==============================] - 21s 48ms/step - loss: 0.0252 - acc: 0.9933 - val_loss: 0.0422 - val_acc: 0.9910\n",
      "Epoch 32/40\n",
      "439/439 [==============================] - 21s 47ms/step - loss: 0.0269 - acc: 0.9931 - val_loss: 0.0424 - val_acc: 0.9910\n",
      "Epoch 33/40\n",
      "439/439 [==============================] - 21s 47ms/step - loss: 0.0257 - acc: 0.9940 - val_loss: 0.0424 - val_acc: 0.9910\n",
      "Epoch 34/40\n",
      "439/439 [==============================] - 21s 47ms/step - loss: 0.0256 - acc: 0.9938 - val_loss: 0.0421 - val_acc: 0.9907\n",
      "Epoch 35/40\n",
      "439/439 [==============================] - 21s 47ms/step - loss: 0.0283 - acc: 0.9934 - val_loss: 0.0422 - val_acc: 0.9907\n",
      "Epoch 36/40\n",
      "439/439 [==============================] - 21s 47ms/step - loss: 0.0267 - acc: 0.9938 - val_loss: 0.0424 - val_acc: 0.9907\n",
      "Epoch 37/40\n",
      "439/439 [==============================] - 21s 47ms/step - loss: 0.0250 - acc: 0.9937 - val_loss: 0.0423 - val_acc: 0.9910\n",
      "Epoch 38/40\n",
      "439/439 [==============================] - 21s 47ms/step - loss: 0.0254 - acc: 0.9934 - val_loss: 0.0422 - val_acc: 0.9907\n",
      "Epoch 39/40\n",
      "439/439 [==============================] - 21s 48ms/step - loss: 0.0260 - acc: 0.9932 - val_loss: 0.0425 - val_acc: 0.9905\n",
      "Epoch 40/40\n",
      "439/439 [==============================] - 21s 47ms/step - loss: 0.0277 - acc: 0.9929 - val_loss: 0.0424 - val_acc: 0.9907\n",
      "Test loss: 0.04242020420849258\n",
      "Test accuracy: 0.9907142857142858\n"
     ]
    }
   ],
   "source": [
    "epochs=40 \n",
    "model.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "history = model.fit_generator(datagen.flow(X_train,Y_train, batch_size=batch_size),\n",
    "                              epochs = epochs, \n",
    "                              validation_data = (X_val,Y_val),\n",
    "                              verbose = 1, \n",
    "                              steps_per_epoch=X_train.shape[0] // batch_size, \n",
    "                              callbacks=[tensorboard,learning_rate_reduction])\n",
    "score = model.evaluate(X_val, Y_val, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"navy\">You can see the test accuracy improved from </font><font color=\"green\">0.9876190476190476</font><font color=\"navy\"> to </font><font color=\"green\">0.9907142857142858.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"navy\">Now let's prepare out submission file.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict results\n",
    "results = model.predict(test)\n",
    "\n",
    "# select the indix with the maximum probability\n",
    "results = np.argmax(results,axis = 1)\n",
    "\n",
    "results = pd.Series(results,name=\"Label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\n",
    "\n",
    "submission.to_csv(\"C://projects//python//kaggle//digits-recognizer//data//digit-recognizer//cnn_mnist_submission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"navy\">My submission scored </font><font color=\"green\">0.99657</font><font color=\"navy\">, which is pretty good considering I am not using any ensemble methods.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"navy\">Now we can use Tensorboard to visualize the learning result.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"navy\">I am using Anaconda. So at Anaconda environment, open a new Terminal. Then type the following</font>\n",
    "<br/>\n",
    "<font color=\"black\">tensorboard --logdir=C:\\projects\\python\\kaggle\\digits-recognizer\\logs</font>\n",
    "<br/>\n",
    "<font color=\"navy\">Once open, click \"allow firewall access\"</font>\n",
    "<font color=\"navy\">Then open a new browser tab, type the location</font>\n",
    "<br/>\n",
    "<font color=\"navy\">http://localhost:6006</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"navy\">Thanks for Yassine Ghouzam of his kernel</font>\n",
    "<a href=\"https://www.kaggle.com/yassineghouzam/introduction-to-cnn-keras-0-997-top-6\" target=\"_blank\">\n",
    "Introduction to CNN Keras - Acc 0.997 (top 8%)</a>\n",
    "<font color=\"navy\">Also inspired from the book <a href=\"https://www.manning.com/books/deep-learning-with-python\">Deep learning with python</a> book by Keras author Fran√ßois Chollet.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"navy\">Please </font><font color=\"green\" size=5>upvote</font><font color=\"navy\"> my post if you find is useful</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
